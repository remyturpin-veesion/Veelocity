# v0.2 GitHub Integration Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Connect to GitHub API, sync repositories/PRs/reviews/comments/commits to local database, expose via REST API.

**Architecture:** BaseConnector ABC defines the interface. GitHubConnector uses httpx to fetch data from GitHub REST API. Data is stored in PostgreSQL via SQLAlchemy models. APScheduler runs periodic sync. API endpoints expose synced data.

**Tech Stack:** httpx (GitHub API calls), SQLAlchemy (models), APScheduler (periodic sync), pytest + respx (mocking HTTP in tests)

---

## Task 1: Add respx and apscheduler to dependencies

**Files:**
- Modify: `backend/pyproject.toml`

**Step 1: Add respx to dev dependencies**

Add `respx>=0.21.1` to `[dependency-groups] dev` in pyproject.toml. respx is used to mock httpx calls in tests.

Add `apscheduler>=3.10.4` to `[project] dependencies` (should already be there, verify).

**Step 2: Lock dependencies**

Run: `cd backend && uv lock`

**Step 3: Verify**

Run: `cd backend && uv run python -c "import respx; print('ok')"`
Expected: `ok`

**Step 4: Commit**

```bash
git add backend/pyproject.toml backend/uv.lock
git commit -m "build(backend): add respx for HTTP mocking in tests"
```

---

## Task 2: BaseConnector ABC + Schemas

**Files:**
- Create: `backend/app/connectors/__init__.py`
- Create: `backend/app/connectors/base.py`
- Create: `backend/app/schemas/__init__.py`
- Create: `backend/app/schemas/connector.py`
- Create: `backend/tests/connectors/__init__.py`
- Create: `backend/tests/connectors/test_base.py`

**Step 1: Create connector schemas**

```python
# backend/app/schemas/connector.py
from datetime import datetime
from pydantic import BaseModel


class SyncResult(BaseModel):
    """Result of a sync operation."""

    connector_name: str
    started_at: datetime
    completed_at: datetime
    items_synced: int
    errors: list[str] = []

    @property
    def success(self) -> bool:
        return len(self.errors) == 0


class ConnectorStatus(BaseModel):
    """Status of a connector."""

    name: str
    connected: bool
    last_sync: datetime | None = None
    last_sync_items: int | None = None
```

**Step 2: Create BaseConnector ABC**

```python
# backend/app/connectors/base.py
from abc import ABC, abstractmethod
from datetime import datetime

from app.schemas.connector import SyncResult


class BaseConnector(ABC):
    """Interface for all data source connectors."""

    @property
    @abstractmethod
    def name(self) -> str:
        """Unique connector name."""
        ...

    @abstractmethod
    async def test_connection(self) -> bool:
        """Test if the connection is valid."""
        ...

    @abstractmethod
    async def sync_all(self, db) -> SyncResult:
        """Full sync of all data."""
        ...

    @abstractmethod
    async def sync_recent(self, db, since: datetime) -> SyncResult:
        """Incremental sync since a given date."""
        ...

    @abstractmethod
    def get_supported_metrics(self) -> list[str]:
        """List metrics this connector supports."""
        ...
```

**Step 3: Write test verifying ABC can't be instantiated**

```python
# backend/tests/connectors/test_base.py
import pytest
from app.connectors.base import BaseConnector


def test_base_connector_cannot_be_instantiated():
    """BaseConnector is abstract and cannot be instantiated."""
    with pytest.raises(TypeError):
        BaseConnector()
```

**Step 4: Run tests**

Run: `cd backend && uv run pytest tests/connectors/ -v`
Expected: PASS

**Step 5: Commit**

```bash
git add backend/app/connectors/ backend/app/schemas/ backend/tests/connectors/
git commit -m "feat(backend): add BaseConnector ABC and connector schemas

- BaseConnector with test_connection, sync_all, sync_recent
- SyncResult and ConnectorStatus Pydantic models"
```

---

## Task 3: SQLAlchemy Models

**Files:**
- Create: `backend/app/models/__init__.py`
- Create: `backend/app/models/github.py`

**Step 1: Create GitHub models**

```python
# backend/app/models/github.py
from datetime import datetime

from sqlalchemy import BigInteger, Boolean, DateTime, ForeignKey, Integer, String, Text
from sqlalchemy.orm import Mapped, mapped_column, relationship

from app.core.database import Base


class Repository(Base):
    __tablename__ = "repositories"

    id: Mapped[int] = mapped_column(primary_key=True)
    github_id: Mapped[int] = mapped_column(BigInteger, unique=True, index=True)
    name: Mapped[str] = mapped_column(String(255))
    full_name: Mapped[str] = mapped_column(String(512), unique=True)
    default_branch: Mapped[str] = mapped_column(String(255), default="main")
    created_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow)
    updated_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    pull_requests: Mapped[list["PullRequest"]] = relationship(back_populates="repository")
    commits: Mapped[list["Commit"]] = relationship(back_populates="repository")


class PullRequest(Base):
    __tablename__ = "pull_requests"

    id: Mapped[int] = mapped_column(primary_key=True)
    github_id: Mapped[int] = mapped_column(BigInteger, unique=True, index=True)
    repo_id: Mapped[int] = mapped_column(ForeignKey("repositories.id"))
    number: Mapped[int] = mapped_column(Integer)
    title: Mapped[str] = mapped_column(String(1024))
    body: Mapped[str | None] = mapped_column(Text, nullable=True)
    state: Mapped[str] = mapped_column(String(50))  # open, closed, merged
    draft: Mapped[bool] = mapped_column(Boolean, default=False)
    author_login: Mapped[str] = mapped_column(String(255))
    author_avatar: Mapped[str | None] = mapped_column(String(512), nullable=True)
    created_at: Mapped[datetime] = mapped_column(DateTime)
    updated_at: Mapped[datetime] = mapped_column(DateTime)
    merged_at: Mapped[datetime | None] = mapped_column(DateTime, nullable=True)
    closed_at: Mapped[datetime | None] = mapped_column(DateTime, nullable=True)
    additions: Mapped[int] = mapped_column(Integer, default=0)
    deletions: Mapped[int] = mapped_column(Integer, default=0)
    commits_count: Mapped[int] = mapped_column(Integer, default=0)

    repository: Mapped["Repository"] = relationship(back_populates="pull_requests")
    reviews: Mapped[list["PRReview"]] = relationship(back_populates="pull_request")
    comments: Mapped[list["PRComment"]] = relationship(back_populates="pull_request")
    commits_rel: Mapped[list["Commit"]] = relationship(back_populates="pull_request")


class PRReview(Base):
    __tablename__ = "pr_reviews"

    id: Mapped[int] = mapped_column(primary_key=True)
    github_id: Mapped[int] = mapped_column(BigInteger, unique=True, index=True)
    pr_id: Mapped[int] = mapped_column(ForeignKey("pull_requests.id"))
    reviewer_login: Mapped[str] = mapped_column(String(255))
    state: Mapped[str] = mapped_column(String(50))  # approved, changes_requested, commented
    submitted_at: Mapped[datetime] = mapped_column(DateTime)

    pull_request: Mapped["PullRequest"] = relationship(back_populates="reviews")


class PRComment(Base):
    __tablename__ = "pr_comments"

    id: Mapped[int] = mapped_column(primary_key=True)
    github_id: Mapped[int] = mapped_column(BigInteger, unique=True, index=True)
    pr_id: Mapped[int] = mapped_column(ForeignKey("pull_requests.id"))
    author_login: Mapped[str] = mapped_column(String(255))
    body: Mapped[str] = mapped_column(Text)
    created_at: Mapped[datetime] = mapped_column(DateTime)

    pull_request: Mapped["PullRequest"] = relationship(back_populates="comments")


class Commit(Base):
    __tablename__ = "commits"

    id: Mapped[int] = mapped_column(primary_key=True)
    sha: Mapped[str] = mapped_column(String(40), unique=True, index=True)
    repo_id: Mapped[int] = mapped_column(ForeignKey("repositories.id"))
    pr_id: Mapped[int | None] = mapped_column(ForeignKey("pull_requests.id"), nullable=True)
    author_login: Mapped[str] = mapped_column(String(255))
    message: Mapped[str] = mapped_column(Text)
    committed_at: Mapped[datetime] = mapped_column(DateTime)

    repository: Mapped["Repository"] = relationship(back_populates="commits")
    pull_request: Mapped["PullRequest | None"] = relationship(back_populates="commits_rel")
```

**Step 2: Create models __init__.py**

```python
# backend/app/models/__init__.py
from app.models.github import Commit, PRComment, PRReview, PullRequest, Repository

__all__ = ["Repository", "PullRequest", "PRReview", "PRComment", "Commit"]
```

**Step 3: Update alembic/env.py to import models**

In `backend/alembic/env.py`, uncomment the model import line:

```python
from app.models import *  # noqa
```

**Step 4: Commit**

```bash
git add backend/app/models/ backend/alembic/env.py
git commit -m "feat(backend): add GitHub SQLAlchemy models

- Repository, PullRequest, PRReview, PRComment, Commit
- Relationships between all models
- Alembic configured to detect models"
```

---

## Task 4: Alembic Migration

**Step 1: Generate migration**

Run: `cd backend && uv run alembic revision --autogenerate -m "add github models"`

**Step 2: Verify migration file was created**

Check `backend/alembic/versions/` for a new file.

**Step 3: Commit**

```bash
git add backend/alembic/versions/
git commit -m "feat(backend): add migration for GitHub models"
```

---

## Task 5: GitHub Connector

**Files:**
- Create: `backend/app/connectors/github.py`
- Create: `backend/tests/connectors/test_github.py`

**Step 1: Write tests for GitHubConnector**

```python
# backend/tests/connectors/test_github.py
import pytest
import respx
from httpx import Response
from datetime import datetime, timezone

from app.connectors.github import GitHubConnector


@pytest.fixture
def connector():
    return GitHubConnector(token="test-token", repos=["owner/repo"])


def test_connector_name(connector):
    assert connector.name == "github"


def test_supported_metrics(connector):
    metrics = connector.get_supported_metrics()
    assert "pr_review_time" in metrics
    assert "throughput" in metrics


@pytest.mark.asyncio
@respx.mock
async def test_test_connection_success(connector):
    respx.get("https://api.github.com/user").mock(
        return_value=Response(200, json={"login": "testuser"})
    )
    result = await connector.test_connection()
    assert result is True


@pytest.mark.asyncio
@respx.mock
async def test_test_connection_failure(connector):
    respx.get("https://api.github.com/user").mock(
        return_value=Response(401, json={"message": "Bad credentials"})
    )
    result = await connector.test_connection()
    assert result is False


@pytest.mark.asyncio
@respx.mock
async def test_fetch_repos(connector):
    respx.get("https://api.github.com/repos/owner/repo").mock(
        return_value=Response(200, json={
            "id": 123,
            "name": "repo",
            "full_name": "owner/repo",
            "default_branch": "main",
        })
    )
    repos = await connector.fetch_repos()
    assert len(repos) == 1
    assert repos[0]["full_name"] == "owner/repo"


@pytest.mark.asyncio
@respx.mock
async def test_fetch_pull_requests(connector):
    respx.get("https://api.github.com/repos/owner/repo/pulls").mock(
        return_value=Response(200, json=[
            {
                "id": 1,
                "number": 42,
                "title": "Test PR",
                "body": "Description",
                "state": "open",
                "draft": False,
                "user": {"login": "dev1", "avatar_url": "https://avatar"},
                "created_at": "2025-01-01T00:00:00Z",
                "updated_at": "2025-01-02T00:00:00Z",
                "merged_at": None,
                "closed_at": None,
                "additions": 10,
                "deletions": 5,
                "commits": 3,
            }
        ])
    )
    prs = await connector.fetch_pull_requests("owner/repo")
    assert len(prs) == 1
    assert prs[0]["number"] == 42
    assert prs[0]["author_login"] == "dev1"


@pytest.mark.asyncio
@respx.mock
async def test_fetch_reviews(connector):
    respx.get("https://api.github.com/repos/owner/repo/pulls/42/reviews").mock(
        return_value=Response(200, json=[
            {
                "id": 100,
                "user": {"login": "reviewer1"},
                "state": "APPROVED",
                "submitted_at": "2025-01-02T10:00:00Z",
            }
        ])
    )
    reviews = await connector.fetch_reviews("owner/repo", 42)
    assert len(reviews) == 1
    assert reviews[0]["reviewer_login"] == "reviewer1"
    assert reviews[0]["state"] == "approved"


@pytest.mark.asyncio
@respx.mock
async def test_fetch_comments(connector):
    respx.get("https://api.github.com/repos/owner/repo/pulls/42/comments").mock(
        return_value=Response(200, json=[
            {
                "id": 200,
                "user": {"login": "dev2"},
                "body": "Looks good",
                "created_at": "2025-01-02T11:00:00Z",
            }
        ])
    )
    comments = await connector.fetch_comments("owner/repo", 42)
    assert len(comments) == 1
    assert comments[0]["author_login"] == "dev2"


@pytest.mark.asyncio
@respx.mock
async def test_fetch_commits(connector):
    respx.get("https://api.github.com/repos/owner/repo/pulls/42/commits").mock(
        return_value=Response(200, json=[
            {
                "sha": "abc123",
                "commit": {
                    "author": {"name": "Dev", "date": "2025-01-01T08:00:00Z"},
                    "message": "Initial commit",
                },
                "author": {"login": "dev1"},
            }
        ])
    )
    commits = await connector.fetch_pr_commits("owner/repo", 42)
    assert len(commits) == 1
    assert commits[0]["sha"] == "abc123"
    assert commits[0]["author_login"] == "dev1"
```

**Step 2: Run tests to verify they fail**

Run: `cd backend && uv run pytest tests/connectors/test_github.py -v`
Expected: FAIL (module not found)

**Step 3: Implement GitHubConnector**

```python
# backend/app/connectors/github.py
from datetime import datetime, timezone

import httpx

from app.connectors.base import BaseConnector
from app.schemas.connector import SyncResult


class GitHubConnector(BaseConnector):
    """Connector for GitHub REST API."""

    BASE_URL = "https://api.github.com"

    def __init__(self, token: str, repos: list[str]):
        self._token = token
        self._repos = repos
        self._client = httpx.AsyncClient(
            base_url=self.BASE_URL,
            headers={
                "Authorization": f"Bearer {token}",
                "Accept": "application/vnd.github.v3+json",
            },
            timeout=30.0,
        )

    @property
    def name(self) -> str:
        return "github"

    def get_supported_metrics(self) -> list[str]:
        return ["pr_review_time", "pr_merge_time", "throughput"]

    async def test_connection(self) -> bool:
        """Test GitHub API connection."""
        response = await self._client.get("/user")
        return response.status_code == 200

    async def fetch_repos(self) -> list[dict]:
        """Fetch configured repositories."""
        repos = []
        for repo_full_name in self._repos:
            response = await self._client.get(f"/repos/{repo_full_name}")
            if response.status_code == 200:
                data = response.json()
                repos.append({
                    "github_id": data["id"],
                    "name": data["name"],
                    "full_name": data["full_name"],
                    "default_branch": data.get("default_branch", "main"),
                })
        return repos

    async def fetch_pull_requests(
        self, repo_full_name: str, state: str = "all", per_page: int = 100
    ) -> list[dict]:
        """Fetch pull requests for a repository."""
        prs = []
        page = 1
        while True:
            response = await self._client.get(
                f"/repos/{repo_full_name}/pulls",
                params={"state": state, "per_page": per_page, "page": page},
            )
            if response.status_code != 200:
                break
            data = response.json()
            if not data:
                break
            for pr in data:
                prs.append({
                    "github_id": pr["id"],
                    "number": pr["number"],
                    "title": pr["title"],
                    "body": pr.get("body"),
                    "state": pr["state"],
                    "draft": pr.get("draft", False),
                    "author_login": pr["user"]["login"],
                    "author_avatar": pr["user"].get("avatar_url"),
                    "created_at": pr["created_at"],
                    "updated_at": pr["updated_at"],
                    "merged_at": pr.get("merged_at"),
                    "closed_at": pr.get("closed_at"),
                    "additions": pr.get("additions", 0),
                    "deletions": pr.get("deletions", 0),
                    "commits_count": pr.get("commits", 0),
                })
            page += 1
        return prs

    async def fetch_reviews(self, repo_full_name: str, pr_number: int) -> list[dict]:
        """Fetch reviews for a pull request."""
        response = await self._client.get(
            f"/repos/{repo_full_name}/pulls/{pr_number}/reviews"
        )
        if response.status_code != 200:
            return []
        return [
            {
                "github_id": review["id"],
                "reviewer_login": review["user"]["login"],
                "state": review["state"].lower(),
                "submitted_at": review["submitted_at"],
            }
            for review in response.json()
        ]

    async def fetch_comments(self, repo_full_name: str, pr_number: int) -> list[dict]:
        """Fetch review comments for a pull request."""
        response = await self._client.get(
            f"/repos/{repo_full_name}/pulls/{pr_number}/comments"
        )
        if response.status_code != 200:
            return []
        return [
            {
                "github_id": comment["id"],
                "author_login": comment["user"]["login"],
                "body": comment["body"],
                "created_at": comment["created_at"],
            }
            for comment in response.json()
        ]

    async def fetch_pr_commits(self, repo_full_name: str, pr_number: int) -> list[dict]:
        """Fetch commits for a pull request."""
        response = await self._client.get(
            f"/repos/{repo_full_name}/pulls/{pr_number}/commits"
        )
        if response.status_code != 200:
            return []
        return [
            {
                "sha": commit["sha"],
                "author_login": commit.get("author", {}).get("login", commit["commit"]["author"]["name"]),
                "message": commit["commit"]["message"],
                "committed_at": commit["commit"]["author"]["date"],
            }
            for commit in response.json()
        ]

    async def sync_all(self, db) -> SyncResult:
        """Full sync: repos, PRs, reviews, comments, commits."""
        started_at = datetime.now(timezone.utc)
        items_synced = 0
        errors = []

        from app.services.sync import SyncService
        sync_service = SyncService(db, self)

        try:
            items_synced = await sync_service.sync_all()
        except Exception as e:
            errors.append(str(e))

        return SyncResult(
            connector_name=self.name,
            started_at=started_at,
            completed_at=datetime.now(timezone.utc),
            items_synced=items_synced,
            errors=errors,
        )

    async def sync_recent(self, db, since: datetime) -> SyncResult:
        """Incremental sync since a given date."""
        started_at = datetime.now(timezone.utc)
        items_synced = 0
        errors = []

        from app.services.sync import SyncService
        sync_service = SyncService(db, self)

        try:
            items_synced = await sync_service.sync_recent(since)
        except Exception as e:
            errors.append(str(e))

        return SyncResult(
            connector_name=self.name,
            started_at=started_at,
            completed_at=datetime.now(timezone.utc),
            items_synced=items_synced,
            errors=errors,
        )

    async def close(self):
        """Close the HTTP client."""
        await self._client.aclose()
```

**Step 4: Run tests**

Run: `cd backend && uv run pytest tests/connectors/ -v`
Expected: All PASS

**Step 5: Commit**

```bash
git add backend/app/connectors/github.py backend/tests/connectors/test_github.py
git commit -m "feat(backend): add GitHubConnector with API methods

- Fetch repos, PRs, reviews, comments, commits
- Pagination support for PRs
- Tests with respx HTTP mocking"
```

---

## Task 6: Sync Service

**Files:**
- Create: `backend/app/services/__init__.py`
- Create: `backend/app/services/sync.py`
- Create: `backend/tests/services/__init__.py`
- Create: `backend/tests/services/test_sync.py`

**Step 1: Write sync service tests**

```python
# backend/tests/services/test_sync.py
import pytest
from unittest.mock import AsyncMock, MagicMock
from datetime import datetime, timezone

from app.services.sync import SyncService


@pytest.fixture
def mock_connector():
    connector = AsyncMock()
    connector.name = "github"
    connector._repos = ["owner/repo"]
    connector.fetch_repos.return_value = [
        {"github_id": 1, "name": "repo", "full_name": "owner/repo", "default_branch": "main"}
    ]
    connector.fetch_pull_requests.return_value = [
        {
            "github_id": 100,
            "number": 1,
            "title": "Test PR",
            "body": "body",
            "state": "closed",
            "draft": False,
            "author_login": "dev1",
            "author_avatar": None,
            "created_at": "2025-01-01T00:00:00Z",
            "updated_at": "2025-01-02T00:00:00Z",
            "merged_at": "2025-01-02T12:00:00Z",
            "closed_at": "2025-01-02T12:00:00Z",
            "additions": 10,
            "deletions": 5,
            "commits_count": 2,
        }
    ]
    connector.fetch_reviews.return_value = [
        {"github_id": 200, "reviewer_login": "reviewer1", "state": "approved", "submitted_at": "2025-01-02T10:00:00Z"}
    ]
    connector.fetch_comments.return_value = [
        {"github_id": 300, "author_login": "dev2", "body": "LGTM", "created_at": "2025-01-02T09:00:00Z"}
    ]
    connector.fetch_pr_commits.return_value = [
        {"sha": "abc123", "author_login": "dev1", "message": "feat: add thing", "committed_at": "2025-01-01T08:00:00Z"}
    ]
    return connector


@pytest.fixture
def mock_db():
    db = AsyncMock()
    db.execute = AsyncMock()
    db.commit = AsyncMock()
    db.flush = AsyncMock()
    return db


@pytest.mark.asyncio
async def test_sync_all_calls_connector_methods(mock_db, mock_connector):
    """sync_all should fetch repos, PRs, reviews, comments, commits."""
    service = SyncService(mock_db, mock_connector)
    count = await service.sync_all()

    mock_connector.fetch_repos.assert_called_once()
    mock_connector.fetch_pull_requests.assert_called_once_with("owner/repo", state="all")
    mock_connector.fetch_reviews.assert_called_once_with("owner/repo", 1)
    mock_connector.fetch_comments.assert_called_once_with("owner/repo", 1)
    mock_connector.fetch_pr_commits.assert_called_once_with("owner/repo", 1)
    assert count > 0
```

**Step 2: Implement SyncService**

```python
# backend/app/services/sync.py
from datetime import datetime, timezone

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from app.connectors.github import GitHubConnector
from app.models.github import Commit, PRComment, PRReview, PullRequest, Repository


class SyncService:
    """Orchestrates data sync from connectors to database."""

    def __init__(self, db: AsyncSession, connector: GitHubConnector):
        self._db = db
        self._connector = connector

    async def sync_all(self) -> int:
        """Full sync: repos, PRs, reviews, comments, commits."""
        count = 0
        repos = await self._connector.fetch_repos()
        count += await self._upsert_repos(repos)

        for repo_data in repos:
            repo = await self._get_repo_by_github_id(repo_data["github_id"])
            if not repo:
                continue

            prs = await self._connector.fetch_pull_requests(repo_data["full_name"], state="all")
            count += await self._upsert_prs(repo.id, prs)

            for pr_data in prs:
                pr = await self._get_pr_by_github_id(pr_data["github_id"])
                if not pr:
                    continue

                reviews = await self._connector.fetch_reviews(repo_data["full_name"], pr_data["number"])
                count += await self._upsert_reviews(pr.id, reviews)

                comments = await self._connector.fetch_comments(repo_data["full_name"], pr_data["number"])
                count += await self._upsert_comments(pr.id, comments)

                commits = await self._connector.fetch_pr_commits(repo_data["full_name"], pr_data["number"])
                count += await self._upsert_commits(repo.id, pr.id, commits)

        await self._db.commit()
        return count

    async def sync_recent(self, since: datetime) -> int:
        """Incremental sync - same as sync_all but filters by date."""
        # For now, same as sync_all. Future: filter PRs by updated_at > since
        return await self.sync_all()

    async def _upsert_repos(self, repos: list[dict]) -> int:
        count = 0
        for data in repos:
            result = await self._db.execute(
                select(Repository).where(Repository.github_id == data["github_id"])
            )
            repo = result.scalar_one_or_none()
            if repo:
                repo.name = data["name"]
                repo.full_name = data["full_name"]
                repo.default_branch = data["default_branch"]
            else:
                repo = Repository(**data)
                self._db.add(repo)
            count += 1
        await self._db.flush()
        return count

    async def _upsert_prs(self, repo_id: int, prs: list[dict]) -> int:
        count = 0
        for data in prs:
            result = await self._db.execute(
                select(PullRequest).where(PullRequest.github_id == data["github_id"])
            )
            pr = result.scalar_one_or_none()
            pr_data = {**data, "repo_id": repo_id}
            # Parse datetime strings
            for field in ("created_at", "updated_at", "merged_at", "closed_at"):
                if pr_data.get(field) and isinstance(pr_data[field], str):
                    pr_data[field] = datetime.fromisoformat(pr_data[field].replace("Z", "+00:00"))
            if pr:
                for key, value in pr_data.items():
                    if key != "github_id":
                        setattr(pr, key, value)
            else:
                pr = PullRequest(**pr_data)
                self._db.add(pr)
            count += 1
        await self._db.flush()
        return count

    async def _upsert_reviews(self, pr_id: int, reviews: list[dict]) -> int:
        count = 0
        for data in reviews:
            result = await self._db.execute(
                select(PRReview).where(PRReview.github_id == data["github_id"])
            )
            existing = result.scalar_one_or_none()
            review_data = {**data, "pr_id": pr_id}
            if review_data.get("submitted_at") and isinstance(review_data["submitted_at"], str):
                review_data["submitted_at"] = datetime.fromisoformat(review_data["submitted_at"].replace("Z", "+00:00"))
            if not existing:
                self._db.add(PRReview(**review_data))
                count += 1
        await self._db.flush()
        return count

    async def _upsert_comments(self, pr_id: int, comments: list[dict]) -> int:
        count = 0
        for data in comments:
            result = await self._db.execute(
                select(PRComment).where(PRComment.github_id == data["github_id"])
            )
            existing = result.scalar_one_or_none()
            comment_data = {**data, "pr_id": pr_id}
            if comment_data.get("created_at") and isinstance(comment_data["created_at"], str):
                comment_data["created_at"] = datetime.fromisoformat(comment_data["created_at"].replace("Z", "+00:00"))
            if not existing:
                self._db.add(PRComment(**comment_data))
                count += 1
        await self._db.flush()
        return count

    async def _upsert_commits(self, repo_id: int, pr_id: int, commits: list[dict]) -> int:
        count = 0
        for data in commits:
            result = await self._db.execute(
                select(Commit).where(Commit.sha == data["sha"])
            )
            existing = result.scalar_one_or_none()
            commit_data = {
                "sha": data["sha"],
                "repo_id": repo_id,
                "pr_id": pr_id,
                "author_login": data["author_login"],
                "message": data["message"],
                "committed_at": datetime.fromisoformat(data["committed_at"].replace("Z", "+00:00")) if isinstance(data["committed_at"], str) else data["committed_at"],
            }
            if not existing:
                self._db.add(Commit(**commit_data))
                count += 1
        await self._db.flush()
        return count

    async def _get_repo_by_github_id(self, github_id: int) -> Repository | None:
        result = await self._db.execute(
            select(Repository).where(Repository.github_id == github_id)
        )
        return result.scalar_one_or_none()

    async def _get_pr_by_github_id(self, github_id: int) -> PullRequest | None:
        result = await self._db.execute(
            select(PullRequest).where(PullRequest.github_id == github_id)
        )
        return result.scalar_one_or_none()
```

**Step 3: Create empty __init__.py files**

```python
# backend/app/services/__init__.py
# backend/tests/services/__init__.py
```

**Step 4: Run tests**

Run: `cd backend && uv run pytest tests/services/ -v`
Expected: PASS

**Step 5: Commit**

```bash
git add backend/app/services/ backend/tests/services/
git commit -m "feat(backend): add SyncService for GitHub data sync

- Upserts repos, PRs, reviews, comments, commits
- Handles datetime parsing from GitHub API
- Idempotent (upsert by github_id/sha)"
```

---

## Task 7: Config Update + Connector Factory

**Files:**
- Modify: `backend/app/core/config.py`
- Create: `backend/app/connectors/factory.py`

**Step 1: Add github_repos to config**

Add to Settings class:

```python
# GitHub
github_token: str | None = None
github_repos: str = ""  # Comma-separated: "owner/repo1,owner/repo2"
```

**Step 2: Create connector factory**

```python
# backend/app/connectors/factory.py
from app.connectors.github import GitHubConnector
from app.core.config import settings


def create_github_connector() -> GitHubConnector | None:
    """Create GitHubConnector from settings. Returns None if not configured."""
    if not settings.github_token or not settings.github_repos:
        return None
    repos = [r.strip() for r in settings.github_repos.split(",") if r.strip()]
    return GitHubConnector(token=settings.github_token, repos=repos)
```

**Step 3: Commit**

```bash
git add backend/app/core/config.py backend/app/connectors/factory.py
git commit -m "feat(backend): add github_repos config and connector factory

- GITHUB_REPOS env var for specifying repos to sync
- Factory creates GitHubConnector from settings"
```

---

## Task 8: API Endpoints

**Files:**
- Create: `backend/app/api/v1/endpoints/__init__.py`
- Create: `backend/app/api/v1/endpoints/connectors.py`
- Create: `backend/app/api/v1/endpoints/github.py`
- Modify: `backend/app/api/v1/router.py`
- Create: `backend/tests/api/test_connectors.py`
- Create: `backend/tests/api/test_github.py`

**Step 1: Create connectors endpoint**

```python
# backend/app/api/v1/endpoints/connectors.py
from fastapi import APIRouter, BackgroundTasks, Depends
from sqlalchemy.ext.asyncio import AsyncSession

from app.connectors.factory import create_github_connector
from app.core.database import get_db
from app.schemas.connector import ConnectorStatus, SyncResult

router = APIRouter(prefix="/connectors", tags=["connectors"])


@router.get("/status", response_model=list[ConnectorStatus])
async def get_connectors_status():
    """Get status of all configured connectors."""
    statuses = []
    github = create_github_connector()
    if github:
        connected = await github.test_connection()
        statuses.append(ConnectorStatus(name="github", connected=connected))
        await github.close()
    return statuses


@router.post("/sync", response_model=SyncResult | None)
async def trigger_sync(db: AsyncSession = Depends(get_db)):
    """Trigger full sync of all connectors."""
    github = create_github_connector()
    if not github:
        return None
    result = await github.sync_all(db)
    await github.close()
    return result
```

**Step 2: Create github endpoint**

```python
# backend/app/api/v1/endpoints/github.py
from fastapi import APIRouter, Depends
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload

from app.core.database import get_db
from app.models.github import Commit, PRComment, PRReview, PullRequest, Repository

router = APIRouter(prefix="/github", tags=["github"])


@router.get("/repos")
async def get_repos(db: AsyncSession = Depends(get_db)):
    """List synced repositories."""
    result = await db.execute(select(Repository).order_by(Repository.full_name))
    repos = result.scalars().all()
    return [
        {
            "id": r.id,
            "github_id": r.github_id,
            "name": r.name,
            "full_name": r.full_name,
            "default_branch": r.default_branch,
        }
        for r in repos
    ]


@router.get("/repos/{repo_id}/prs")
async def get_repo_prs(repo_id: int, db: AsyncSession = Depends(get_db)):
    """List pull requests for a repository."""
    result = await db.execute(
        select(PullRequest)
        .where(PullRequest.repo_id == repo_id)
        .order_by(PullRequest.created_at.desc())
    )
    prs = result.scalars().all()
    return [
        {
            "id": pr.id,
            "number": pr.number,
            "title": pr.title,
            "state": pr.state,
            "author_login": pr.author_login,
            "created_at": pr.created_at,
            "merged_at": pr.merged_at,
        }
        for pr in prs
    ]


@router.get("/prs/{pr_id}")
async def get_pr_detail(pr_id: int, db: AsyncSession = Depends(get_db)):
    """Get PR with reviews, comments, and commits."""
    result = await db.execute(
        select(PullRequest)
        .where(PullRequest.id == pr_id)
        .options(
            selectinload(PullRequest.reviews),
            selectinload(PullRequest.comments),
            selectinload(PullRequest.commits_rel),
        )
    )
    pr = result.scalar_one_or_none()
    if not pr:
        return {"error": "PR not found"}
    return {
        "id": pr.id,
        "number": pr.number,
        "title": pr.title,
        "body": pr.body,
        "state": pr.state,
        "draft": pr.draft,
        "author_login": pr.author_login,
        "created_at": pr.created_at,
        "merged_at": pr.merged_at,
        "additions": pr.additions,
        "deletions": pr.deletions,
        "reviews": [
            {"reviewer_login": r.reviewer_login, "state": r.state, "submitted_at": r.submitted_at}
            for r in pr.reviews
        ],
        "comments": [
            {"author_login": c.author_login, "body": c.body, "created_at": c.created_at}
            for c in pr.comments
        ],
        "commits": [
            {"sha": c.sha, "author_login": c.author_login, "message": c.message, "committed_at": c.committed_at}
            for c in pr.commits_rel
        ],
    }
```

**Step 3: Create empty __init__.py**

```python
# backend/app/api/v1/endpoints/__init__.py
```

**Step 4: Update router.py**

```python
# backend/app/api/v1/router.py
from fastapi import APIRouter

from app.api.v1.endpoints import connectors, github

api_router = APIRouter()

api_router.include_router(connectors.router)
api_router.include_router(github.router)


@api_router.get("/health")
async def health_check():
    """Health check endpoint."""
    return {"status": "healthy"}
```

**Step 5: Write API tests**

```python
# backend/tests/api/test_connectors.py
import pytest
from unittest.mock import patch, AsyncMock


@pytest.mark.asyncio
async def test_connectors_status_no_config(client):
    """Without GITHUB_TOKEN, returns empty list."""
    response = await client.get("/api/v1/connectors/status")
    assert response.status_code == 200
    assert response.json() == []
```

**Step 6: Run all tests**

Run: `cd backend && uv run pytest -v`
Expected: All PASS

**Step 7: Commit**

```bash
git add backend/app/api/ backend/tests/api/
git commit -m "feat(backend): add connectors and github API endpoints

- GET /connectors/status - connector health
- POST /connectors/sync - trigger full sync
- GET /github/repos - list synced repos
- GET /github/repos/{id}/prs - list PRs
- GET /github/prs/{id} - PR detail with reviews/comments/commits"
```

---

## Task 9: APScheduler Integration

**Files:**
- Modify: `backend/app/main.py`
- Create: `backend/app/services/scheduler.py`

**Step 1: Create scheduler service**

```python
# backend/app/services/scheduler.py
import logging
from datetime import datetime, timedelta, timezone

from apscheduler.schedulers.asyncio import AsyncIOScheduler

from app.connectors.factory import create_github_connector
from app.core.database import async_session_maker

logger = logging.getLogger(__name__)

scheduler = AsyncIOScheduler()


async def run_sync():
    """Run sync job for all configured connectors."""
    github = create_github_connector()
    if not github:
        logger.info("No GitHub connector configured, skipping sync")
        return

    async with async_session_maker() as db:
        since = datetime.now(timezone.utc) - timedelta(hours=1)
        result = await github.sync_recent(db, since)
        logger.info(f"Sync complete: {result.items_synced} items, {len(result.errors)} errors")

    await github.close()


def start_scheduler():
    """Start the periodic sync scheduler."""
    scheduler.add_job(run_sync, "interval", hours=1, id="github_sync", replace_existing=True)
    scheduler.start()
    logger.info("Scheduler started: sync every 1 hour")


def stop_scheduler():
    """Stop the scheduler."""
    scheduler.shutdown(wait=False)
```

**Step 2: Update main.py with lifespan**

```python
# backend/app/main.py
from contextlib import asynccontextmanager

from fastapi import FastAPI

from app.api.v1.router import api_router
from app.core.config import settings
from app.services.scheduler import run_sync, start_scheduler, stop_scheduler


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Startup: run initial sync + start scheduler. Shutdown: stop scheduler."""
    await run_sync()
    start_scheduler()
    yield
    stop_scheduler()


app = FastAPI(
    title=settings.app_name,
    description="Developer analytics platform measuring DORA metrics",
    version="0.2.0",
    lifespan=lifespan,
)

app.include_router(api_router, prefix="/api/v1")


@app.get("/")
async def root():
    """Root endpoint."""
    return {"message": f"Welcome to {settings.app_name}"}
```

**Step 3: Run all tests**

Run: `cd backend && uv run pytest -v`
Expected: All PASS

Note: The lifespan won't run during tests (httpx ASGITransport doesn't trigger lifespan by default).

**Step 4: Commit**

```bash
git add backend/app/main.py backend/app/services/scheduler.py
git commit -m "feat(backend): add APScheduler for periodic GitHub sync

- Sync on startup
- Periodic sync every 1 hour
- Lifespan context manager for startup/shutdown"
```

---

## Task 10: Update .env.example and Documentation

**Files:**
- Modify: `infra/docker/.env.example`
- Modify: `infra/docker/docker-compose.yml`

**Step 1: Add GITHUB_REPOS to .env.example**

Add:
```bash
GITHUB_REPOS=owner/repo1,owner/repo2
```

**Step 2: Add GITHUB_REPOS to docker-compose backend environment**

Add `GITHUB_REPOS: ${GITHUB_REPOS:-}` to backend service environment.

**Step 3: Commit**

```bash
git add infra/ CLAUDE.md
git commit -m "docs: add GITHUB_REPOS to env config

- .env.example documents all required variables
- docker-compose passes GITHUB_REPOS to backend"
```

---

## Task 11: Final Verification

**Step 1: Run all tests**

Run: `cd backend && uv run pytest -v`
Expected: All PASS

**Step 2: Start backend and verify endpoints**

Run: `cd backend && uv run uvicorn app.main:app --reload`

Test:
```bash
curl http://localhost:8000/api/v1/health
curl http://localhost:8000/api/v1/connectors/status
curl http://localhost:8000/api/v1/github/repos
```

**Step 3: Verify with real GitHub token (manual)**

Set `GITHUB_TOKEN` and `GITHUB_REPOS` in environment, restart, and verify sync works.

---

## Summary

After completing all tasks, v0.2 delivers:

- [x] BaseConnector ABC interface
- [x] GitHubConnector (repos, PRs, reviews, comments, commits)
- [x] SQLAlchemy models for all GitHub entities
- [x] Alembic migration
- [x] SyncService for data orchestration
- [x] API endpoints (connectors status, sync, repos, PRs)
- [x] APScheduler (sync on startup + every hour)
- [x] Tests with HTTP mocking (respx)

**Next version (v0.3):** GitHub Actions connector + DORA metrics
